{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  _______________ DATA 620- Week 10/11 Document Classifier _______________\n",
    "This project will create a Document classifier to classify emails into spam and ham. <br/>\n",
    "The dataset can be downloaded from http://www.aueb.gr/users/ion/data/enron-spam/<br/>\n",
    "After navigating to the above URL, click on the Enron1 link to download the Enron1 dataset.<br/>\n",
    "After expanding the dataset archive you will have see a enron1 folder that in-turn contains the ham and spam folders.<br/>\n",
    "The dataFolder variable in the code should point to the enron1 folder.<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DATASET URL: http://www.aueb.gr/users/ion/data/enron-spam/\n",
    "# Update the dataFolder to point to your enron1 folder path.\n",
    "dataFolder='/Users/burton/000-Semester_06_CUNY/620_Web_Analytics/Week_10/enron1'\n",
    "\n",
    "from __future__ import print_function, division\n",
    "import nltk\n",
    "from nltk import word_tokenize, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import NaiveBayesClassifier, classify\n",
    "import os\n",
    "import random\n",
    "from collections import Counter\n",
    "stoplist = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the function to extract features.\n",
    "def extractFeatures(emailList):\n",
    "    featureList=[]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for email in emailList:\n",
    "        features={}\n",
    "        tokens=[]\n",
    "        for word in word_tokenize(unicode(email[0], errors='ignore')):\n",
    "            tokens.append(lemmatizer.lemmatize(word.lower()))\n",
    "        for token in tokens:\n",
    "            if not token in stoplist:\n",
    "                features[token]=True\n",
    "        featureList.append((features,email[1]))\n",
    "    return featureList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Update the data folder path to match yours.\n",
    "hamEmails=[]\n",
    "spamEmails=[]\n",
    "for file in os.listdir(dataFolder + '/ham'):\n",
    "    hamEmails.append(open(dataFolder + '/ham/' + file, 'r').read())\n",
    "for file in os.listdir(dataFolder + '/spam'):\n",
    "    spamEmails.append(open(dataFolder + '/spam/' + file, 'r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hamAndSpamEmails = []\n",
    "for email in spamEmails:\n",
    "    hamAndSpamEmails.append((email, 'spam'))\n",
    "for email in hamEmails:\n",
    "    hamAndSpamEmails.append((email, 'ham'))\n",
    "random.shuffle(hamAndSpamEmails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emailFeatures = extractFeatures(hamAndSpamEmails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainSetSize = int(len(emailFeatures)*0.8)\n",
    "testSetSize = len(emailFeatures)-trainSetSize\n",
    "train_set, test_set = emailFeatures[:trainSetSize], emailFeatures[trainSetSize:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier = NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set Accuracy is : 0.958665699782\n",
      "Test set Accuracy is : 0.954589371981\n"
     ]
    }
   ],
   "source": [
    "trainingAccuracy = classify.accuracy(classifier, train_set)\n",
    "testAccuracy = classify.accuracy(classifier, test_set)\n",
    "print('Training set Accuracy is : ' + str(trainingAccuracy))\n",
    "print('Test set Accuracy is : ' + str(testAccuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "               forwarded = True              ham : spam   =    196.9 : 1.0\n",
      "                     hou = True              ham : spam   =    186.2 : 1.0\n",
      "                    2004 = True             spam : ham    =    156.3 : 1.0\n",
      "            prescription = True             spam : ham    =    144.6 : 1.0\n",
      "                     nom = True              ham : spam   =    123.0 : 1.0\n",
      "                    pain = True             spam : ham    =    112.8 : 1.0\n",
      "                   meter = True              ham : spam   =    107.6 : 1.0\n",
      "                    2005 = True             spam : ham    =     99.5 : 1.0\n",
      "              nomination = True              ham : spam   =     89.5 : 1.0\n",
      "              medication = True             spam : ham    =     89.4 : 1.0\n",
      "                     ect = True              ham : spam   =     82.8 : 1.0\n",
      "                  dealer = True             spam : ham    =     79.4 : 1.0\n",
      "                creative = True             spam : ham    =     74.4 : 1.0\n",
      "                    2001 = True              ham : spam   =     73.9 : 1.0\n",
      "                     ali = True             spam : ham    =     72.7 : 1.0\n",
      "                  differ = True             spam : ham    =     71.0 : 1.0\n",
      "                featured = True             spam : ham    =     71.0 : 1.0\n",
      "                     ibm = True             spam : ham    =     69.4 : 1.0\n",
      "                  reader = True             spam : ham    =     67.7 : 1.0\n",
      "               complaint = True             spam : ham    =     59.3 : 1.0\n",
      "                congress = True             spam : ham    =     59.3 : 1.0\n",
      "                   epson = True             spam : ham    =     59.3 : 1.0\n",
      "                     713 = True              ham : spam   =     58.1 : 1.0\n",
      "                    draw = True             spam : ham    =     57.7 : 1.0\n",
      "                    sony = True             spam : ham    =     57.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
