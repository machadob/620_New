{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### City University of New York | IS620 | Web Analytics\n",
    "\n",
    "# Project 4  :  Bayesian Sense Tag Classifier with Python and NLTK\n",
    "\n",
    "***\n",
    "\n",
    "**We will use the senseval corpus to build a Sense Tag classifier.\n",
    "We start by reading the instances for a particular sense (in our case 'hard').**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import senseval\n",
    "\n",
    "import nltk\n",
    "import random\n",
    "\n",
    "instances = senseval.instances('hard.pos')\n",
    "size = int(0.9 * len(instances))\n",
    "train, test = instances[size:], instances[:size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We have loaded the instances in the 'instances' variable. We will now display three instances (from 1 to 3). \n",
    "Notice that each instance has a position attribute that denotes that position of the sense ('hard' in our case) within the set of words. \n",
    "We will use the position to create a feature set which will be composed of the words and tags before and after the sense word.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SensevalInstance(word=u'hard-a', position=10, context=[('clever', 'NNP'), ('white', 'NNP'), ('house', 'NNP'), ('``', '``'), ('spin', 'VB'), ('doctors', 'NNS'), (\"''\", \"''\"), ('are', 'VBP'), ('having', 'VBG'), ('a', 'DT'), ('hard', 'JJ'), ('time', 'NN'), ('helping', 'VBG'), ('president', 'NNP'), ('bush', 'NNP'), ('explain', 'VB'), ('away', 'RB'), ('the', 'DT'), ('economic', 'JJ'), ('bashing', 'NN'), ('that', 'IN'), ('low-and', 'JJ'), ('middle-income', 'JJ'), ('workers', 'NNS'), ('are', 'VBP'), ('taking', 'VBG'), ('these', 'DT'), ('days', 'NNS'), ('.', '.')], senses=('HARD1',)),\n",
       " SensevalInstance(word=u'hard-a', position=3, context=[('i', 'PRP'), ('find', 'VBP'), ('it', 'PRP'), ('hard', 'JJ'), ('to', 'TO'), ('believe', 'VB'), ('that', 'IN'), ('the', 'DT'), ('sacramento', 'NNP'), ('river', 'NNP'), ('will', 'MD'), ('ever', 'RB'), ('be', 'VB'), ('quite', 'RB'), ('the', 'DT'), ('same', 'JJ'), (',', ','), ('although', 'IN'), ('i', 'PRP'), ('certainly', 'RB'), ('wish', 'VBP'), ('that', 'IN'), ('i', 'PRP'), (\"'m\", 'VBP'), ('wrong', 'JJ'), ('.', '.')], senses=('HARD1',)),\n",
       " SensevalInstance(word=u'hard-a', position=15, context=[('now', 'RB'), ('when', 'WRB'), ('you', 'PRP'), ('get', 'VBP'), ('bad', 'JJ'), ('credit', 'NN'), ('data', 'NNS'), ('or', 'CC'), ('are', 'VBP'), ('confused', 'VBN'), ('with', 'IN'), ('another', 'DT'), ('person', 'NN'), (',', ','), ('the', 'DT'), ('hard', 'JJ'), ('part', 'NN'), ('in', 'IN'), ('correcting', 'VBG'), ('the', 'DT'), ('mistake', 'NN'), ('is', 'VBZ'), ('not', 'RB'), ('even', 'RB'), ('knowing', 'VBG'), ('where', 'WRB'), ('it', 'PRP'), ('is', 'VBZ'), ('recorded', 'VBN'), (',', ','), ('let', 'VB'), ('alone', 'RB'), ('having', 'VBG'), ('access', 'NN'), ('.', '.')], senses=('HARD1',))]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instances[1:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Following is an example of getting the sense label. We will use this during creation of the feature set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HARD1'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instances[0].senses[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will now define our feature set. As noted before, we will use the 'position' atrribute of the instance to find the word and tag combination of the previous word. If the position is zero, there is no previous word, so we will use the next word in that case. The previous word and tag in case of zero position will be hard-coded to 'START' (Start Of Sentence).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getFeatures(instance):\n",
    "    featureList = dict()\n",
    "    position = instance.position\n",
    "#Check if the position is greater than 0. If it is, we have a previous word. Otherwise we just have following words.\n",
    "    if position > 0:\n",
    "        featureList['previousWord'] = instance.context[position - 1][0]\n",
    "        featureList['previousTag'] = instance.context[position - 1][1]\n",
    "        featureList['nextWord'] = instance.context[position + 1][0]\n",
    "        featureList['nextTag'] = instance.context[position + 1][1]\n",
    "    else:  \n",
    "        featureList['previousWord'] = 'START'\n",
    "        featureList['previousTag'] = 'START'        \n",
    "        featureList['nextWord'] = instance.context[position + 1][0]\n",
    "        featureList['nextTag'] = instance.context[position + 1][1]\n",
    "    return featureList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will now build our dataset with features by calling the 'getFeatures' function defined above for each instance object. The sense will be fetched thorough the 'senses' attribute of the instance.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataSet = []\n",
    "for instance in instances:\n",
    "    if len(instance.senses) == 1:\n",
    "        featuresForInstance = getFeatures(instance)\n",
    "        senseForInstance = instance.senses[0]\n",
    "        dataSet.append((featuresForInstance, senseForInstance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will now randomly shuffle the data set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.shuffle(dataSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will print out the size of the data set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4333"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Following are the first 10 entries from the data set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'nextTag': 'TO',\n",
       "   'nextWord': 'to',\n",
       "   'previousTag': 'VBP',\n",
       "   'previousWord': 'are'},\n",
       "  'HARD1'),\n",
       " ({'nextTag': 'PRP',\n",
       "   'nextWord': 'it',\n",
       "   'previousTag': 'WRB',\n",
       "   'previousWord': 'how'},\n",
       "  'HARD1'),\n",
       " ({'nextTag': 'NN',\n",
       "   'nextWord': 'day',\n",
       "   'previousTag': 'DT',\n",
       "   'previousWord': 'the'},\n",
       "  'HARD1'),\n",
       " ({'nextTag': 'NN',\n",
       "   'nextWord': 'question',\n",
       "   'previousTag': 'DT',\n",
       "   'previousWord': 'a'},\n",
       "  'HARD1'),\n",
       " ({'nextTag': 'NN',\n",
       "   'nextWord': 'look',\n",
       "   'previousTag': ',',\n",
       "   'previousWord': ','},\n",
       "  'HARD2'),\n",
       " ({'nextTag': 'NNS',\n",
       "   'nextWord': 'shoes',\n",
       "   'previousTag': 'PRP$',\n",
       "   'previousWord': 'their'},\n",
       "  'HARD3'),\n",
       " ({'nextTag': 'NN',\n",
       "   'nextWord': 'work',\n",
       "   'previousTag': 'PRP$',\n",
       "   'previousWord': 'their'},\n",
       "  'HARD2'),\n",
       " ({'nextTag': 'NN',\n",
       "   'nextWord': 'thinking',\n",
       "   'previousTag': 'IN',\n",
       "   'previousWord': 'of'},\n",
       "  'HARD2'),\n",
       " ({'nextTag': 'TO',\n",
       "   'nextWord': 'to',\n",
       "   'previousTag': 'RB',\n",
       "   'previousWord': 'sometimes'},\n",
       "  'HARD1'),\n",
       " ({'nextTag': 'TO',\n",
       "   'nextWord': 'to',\n",
       "   'previousTag': 'VBZ',\n",
       "   'previousWord': \"'s\"},\n",
       "  'HARD1')]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSet[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will now split the data set into training, dev and test sets. We will use 350 entries for the dev and test set each, and use the remaining for the training set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainingSetStartLocation = 700 # Training set starts from 700 to the end of the list\n",
    "devSetSize = 350 # Dev set starts at 0 and ends at 350\n",
    "trainingSet = dataSet[trainingSetStartLocation:]\n",
    "devSet = dataSet[:devSetSize]\n",
    "testSet = dataSet[devSetSize:trainingSetStartLocation] # Remaining is the test set from 350 to 700"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We now print out the sizes of the various data sets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Training set size is : 3633\n",
      "The Dev set size is : 350\n",
      "The Test set size is : 350\n"
     ]
    }
   ],
   "source": [
    "print('The Training set size is : ' + str(len(trainingSet)))\n",
    "print('The Dev set size is : ' + str(len(devSet)))\n",
    "print('The Test set size is : ' + str(len(testSet)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We now create the bayes classifier and train it with the training set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(trainingSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will now run the classifier on the Dev set and print it's classification accuracy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The Dev set classification accuracy is : ', 0.8885714285714286)\n"
     ]
    }
   ],
   "source": [
    "devSetAccuracy = nltk.classify.accuracy(classifier, devSet)\n",
    "print (\"The Dev set classification accuracy is : \", devSetAccuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will now run the classifier on the Test set and print it's classification accuracy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The Test set classification accuracy is : ', 0.8942857142857142)\n"
     ]
    }
   ],
   "source": [
    "testSetAccuracy = nltk.classify.accuracy(classifier, testSet)\n",
    "print (\"The Test set classification accuracy is : \", testSetAccuracy)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
